{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://raw.githubusercontent.com/ramiro999/pytorch-exploration/main/images/Banner%20Hands-on-ResNet.png\" width=100%>"
      ],
      "metadata": {
        "id": "2UXqqoQ_r30I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#4C5FDA'> **ResNet: Redes neuronales residuales** </font>"
      ],
      "metadata": {
        "id": "pc88F59u18zF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet, o Red Residual, es un tipo de red neuronal convolucional diseñada para facilitar el entrenamiento de redes muy profundas. Fue introducida por Kaiming He y otros en el trabajo <font color=\"EB9A54\">\"Deep Residual Learning for Image Recognition\"</font> durante el ILSVRC de 2015, donde ganó el primer lugar en varias categorías."
      ],
      "metadata": {
        "id": "qb0yWo9R3ic_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"EB9A54\">**¿Por qué utilizar ResNet?**</font>\n",
        "\n",
        "Facilita el entrenamiento de redes profundas: Uno de los principales desafíos en el entrenamiento de redes profundas es el problema de la desaparición/exploración de gradientes. ResNet aborda esto mediante el uso de conexiones residuales que permiten que los gradientes fluyan directamente a través de las capas sin pasar por transformaciones lineales, facilitando el entrenamiento de redes con cientos o incluso miles de capas.\n",
        "\n",
        "- Reutilización de características: Las conexiones de salto (skip connections) permiten que la red ajuste la información y reutilice las características aprendidas anteriormente, lo cual es eficaz para la generalización.\n",
        "\n",
        "- Flexibilidad y adaptabilidad: ResNet ha demostrado ser efectiva en una variedad de tareas de visión por computadora más allá de la clasificación de imágenes, como la detección de objetos y la segmentación semántica.\n",
        "\n",
        "<font color=\"EB9A54\">**Beneficios sobre otras redes neuronales**</font>\n",
        "\n",
        "- Reducción del problema del desvanecimiento de gradientes: A diferencia de las redes convencionales donde el gradiente puede desvanecerse a medida que aumenta la profundidad, las conexiones residuales en ResNet permiten que el gradiente se propague eficazmente a través de muchas más capas.\n",
        "\n",
        "- Mejor rendimiento con mayor profundidad: Mientras que en redes convencionales el rendimiento puede empezar a degradarse o saturarse a medida que la red se profundiza, ResNet puede escalar eficazmente a cientos de capas sin degradación del rendimiento.\n",
        "\n",
        "- Eficiencia en entrenamiento y convergencia más rápida: Las conexiones residuales mejoran la eficiencia del entrenamiento permitiendo convergencias más rápidas con menores tasas de error.\n",
        "\n",
        "- Versatilidad y robustez: ResNet ha establecido nuevos estándares en varios benchmarks y competiciones, demostrando su robustez y versatilidad en diferentes dominios de aplicación."
      ],
      "metadata": {
        "id": "EFovKLkn389D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://raw.githubusercontent.com/ramiro999/pytorch-exploration/main/images/resnet.png\" >"
      ],
      "metadata": {
        "id": "VTtMl2eo588o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PyTorch stuff\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "from torch import optim, nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms as T\n",
        "from torchvision import models, datasets\n",
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ],
      "metadata": {
        "id": "UKEmEmYG6vD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#4C5FDA'> **ResNet56** </font>"
      ],
      "metadata": {
        "id": "9dbK8iXV7FpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MLTwDjmJQZO"
      },
      "outputs": [],
      "source": [
        "conv_k_3 = lambda channel1, channel2, stride: nn.Conv2d(channel1, channel2, stride = stride, kernel_size=3, padding=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class residual_block(nn.Module):\n",
        "\n",
        "\"\"\"\n",
        "    Implementa un bloque residual que contiene dos capas convolucionales con una conexión residual.\n",
        "    SE puede modificar el tamaño de los mapas de activación a través de la opción `change_size`.\n",
        "\n",
        "    Atributos:\n",
        "        conv1 (nn.Module): Primera capa convolucional del bloque.\n",
        "        bn1 (nn.Module): Primera capa de normalización por lotes.\n",
        "        conv2 (nn.Module): Segunda capa convolucional del bloque.\n",
        "        bn2 (nn.Module): Segunda capa de normalización por lotes.\n",
        "        residual (nn.Module, opcional): Capa adicional para adaptar las dimensiones del tensor de entrada al tamaño deseado.\n",
        "    \"\"\"\n",
        "\n",
        "def __init__(self, in_channel, out_channel, stride=1, change_size = True):\n",
        "    super().__init__()\n",
        "    self.conv1 = conv_k_3(in_channel, out_channel, stride)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "    self.conv2 = conv_k_3(out_channel, out_channel, 1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "    # Condicional para adaptar la dimensión del tensor de entrada a la salida deseada\n",
        "    if change_size:\n",
        "      self.residual = nn.Sequential(nn.Conv2d(in_channel,\n",
        "                                              out_channel,\n",
        "                                              kernel__size=1,\n",
        "                                              stide=stride,\n",
        "                                    nn.BatchNorm2d(out_channel))\n",
        "                                    )\n",
        "\n",
        "def forward(self, x):\n",
        "  identity = x if not self.change_size else self.residual(x)  # Calcula la identidad, que es x o una versión adaptada de x si se cambia el tamaño\n",
        "  y = F.relu(self.bn1(self.conv1(x)))\n",
        "  y = self.bn2(self.conv2(y))\n",
        "  y += identity # Suma la identidad al resultado de las capas convolucionales\n",
        "  return F.relu(y) # Aplica la activación ReLU antes de devolver el resultado"
      ],
      "metadata": {
        "id": "sMw5yW2u7ApO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Q6LowRo-kwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#4C5FDA'> **Referencias** </font>\n",
        "\n",
        "He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR).\n",
        "\n",
        "https://arxiv.org/abs/1512.03385\n",
        "\n",
        "---\n",
        "\n",
        "Canziani, A., Paszke, A., & Culurciello, E. (2016). An Analysis of Deep Neural Network Models for Practical Applications.\n",
        "\n",
        "https://arxiv.org/abs/1605.07678\n",
        "\n",
        "---\n",
        "\n",
        "Fundamentos de la implementación\n",
        "\n",
        "https://github.com/JACantoral/DL_fundamentals/tree/main\n"
      ],
      "metadata": {
        "id": "vs94zlrf4VCB"
      }
    }
  ]
}